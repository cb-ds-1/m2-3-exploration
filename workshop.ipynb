{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Birth Rates\n",
    "\n",
    "The data on US births, provided by the CDC is in `data/births.csv`.\n",
    "\n",
    "Reproduce the following plot of births by gender over time given the data:\n",
    "\n",
    "![](births_gender.png)\n",
    "\n",
    "Note the `1e6` on the y axis for scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('data/births.csv')\n",
    "print(df.head(5))\n",
    "df.loc[df['gender'] == 'F'].groupby(['year']).sum().reset_index()['births'].plot()\n",
    "df.loc[df['gender'] == 'M'].groupby(['year']).sum().reset_index()['births'].plot()\n",
    "plt.legend(['F', 'M'], title='gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Births anomalies\n",
    "\n",
    "This was analyzed by beloved statistician Andrew Gelman [here](http://andrewgelman.com/2012/06/14/cool-ass-signal-processing-using-gaussian-processes/), leading to this plot:\n",
    "\n",
    "![](births_gp100.png)\n",
    "\n",
    "Explain all three plots in Gelman's figure. \n",
    "\n",
    "**1.2:** What is the periodic component? What is the residual? Use your research skills to learn then explain it (in english)."
   ]
  },
  {
   "source": [
    "## Explain the plots \n",
    "It represtends the variation of the ratio of the average number of births for each day in a year over the average number of births over each day of a year. \n",
    "\n",
    "## The Periodic Component \n",
    "It's uses constructive interference to clear noise. it gives us a clearer view into periodic changes and other anomalies in the plot. For example, on the upper plot, the daily birth line fluctuates so regularily that we might miss high or low trends.\n",
    "\n",
    "## Residual \n",
    "It's the distance between a point and the regression line. The bottom plot takes all the points from the first plot and represent the distances from the smoothed line. It gives us another way to analyse the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Holiday Anomalies Plot\n",
    "\n",
    "Reproduce *as best you can* the first of the 3 figures from Andrew Gelman's blog post (your plot may have small differences)\n",
    "\n",
    "**1.3.1:** Reproduce the births line in a plot. Hint: Make the x axis a `pd.datetime` object\n",
    "\n",
    "**1.3.2:** Reproduce the `smoothed` line. Hint: use a rolling window average\n",
    "\n",
    "**1.3.3:** Reproduce the entire figure with the mean line as a horizontal. You can make the y axis total births instead of a % deviation from mean axis (they'll look the same anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('data/births.csv')\n",
    "\n",
    "#data cleaning \n",
    "df = df.dropna()\n",
    "df = df.loc[(df['day'] > 0) & (df['day'] <=31)]\n",
    "df = df.loc[(df['month'] > 0 & (df['month'] <= 12))]\n",
    "\n",
    "\n",
    "#Create the datetime\n",
    "df.day = df.day.astype(int)\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
    "\n",
    "# get day of the year\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "\n",
    "\n",
    "#grouping by day of year\n",
    "df = df.groupby(['day_of_year']).sum().reset_index()\n",
    "df['births'] = df['births'] / df['births'].mean() * 100\n",
    "df['mean'] = 100 \n",
    "\n",
    "# rolling average pandas as way to calculate it for us. \n",
    "rolling = df.rolling(7, center=True)\n",
    "s=pd.Series([100])\n",
    "\n",
    "\n",
    "ax = df['births'].plot(color='orange')\n",
    "rolling.mean()['births'].plot(color=\"blue\")\n",
    "df['mean'].plot(color=\"red\")\n",
    "ax.set_xlabel(\"Day of the year\")\n",
    "ax.set_ylabel(\"Relative number of births\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Recipe Database\n",
    "\n",
    "### 2.1 \n",
    "\n",
    "Load the JSON recipe database we saw in lecture 4.\n",
    "\n",
    "How many of the recipes are for breakfast food? Hint: The `description` would contain the work \"breakfast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "recipes = pd.read_json('data/recipe.json.gz', compression='infer', lines = True)\n",
    "\n",
    "print('The number of breakfast recipes is:', len( recipes[recipes.description.str.contains(\"breakfast\", na=False)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 A simple recipe recommender\n",
    "\n",
    "Let's build a recipe recommender: given a list of basic ingredients, find a recipe that uses all those ingredients.\n",
    "\n",
    "Here is the list of ingredients that can be asked for:\n",
    "\n",
    "```\n",
    "['salt', 'pepper', 'oregano', 'sage', 'parsley',\n",
    " 'rosemary', 'tarragon', 'thyme', 'paprika', 'cumin']\n",
    "```\n",
    "\n",
    "**Hint:** Build a new column for each of the ingredients that indicates whether that ingredient is in the recipe.\n",
    "\n",
    "**example:**\n",
    "```\n",
    "recommend_ingredients([\"parsley\", \"paprika\", \"tarragon\"], df)\n",
    "\n",
    "result: \n",
    "# The rows where these 3 ingredients are in the recipe\n",
    "[2069, 74964, 93768, 113926, 137686, 140530, 158475, 158486, 163175, 165243]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_ingredients(ingredients_list, df):\n",
    "    \n",
    "    \n",
    "    for ingredient in ingredients_list:\n",
    "        df[ingredient] = df['ingredients'].str.lower().str.contains(ingredient)\n",
    "    remaining = df\n",
    "    for ingredient in ingredients_list:\n",
    "        remaining = remaining.loc[remaining[ingredient] == True]\n",
    "    \n",
    "    return remaining\n",
    "    \n",
    "print(f' there are {len(recommend_ingredients([\"parsley\", \"paprika\"], recipes))} with parsley and paprika')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Movies!\n",
    "\n",
    "Recall the [Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset) from lecture 4. It's made up of several tables which we've played with in lecture 4.\n",
    "\n",
    "The tables have common columns (`id` and `movie_id`) around which you can merge and join tables.\n",
    "\n",
    "### 3.1 best director\n",
    "\n",
    "Your task is to find **The best director** in terms of average ratings of his movies. This can be from the `ratings` or `ratings_small` table, or simply the vote average in the `metadata` table. The director can be found in the `cast` table.\n",
    "\n",
    "You will have to use all of your skills to get this done, between using groupbys and merging multiple tables together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file \n",
    "df_credit = pd.read_csv('data/credits.csv')\n",
    "\n",
    "df_movies_metadata = pd.read_csv('data/movies_metadata.csv')\n",
    "df_credit.crew = df_credit.crew.apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_finder(credit_crew):\n",
    "    dir_name = None\n",
    "    for rows in credit_crew:\n",
    "        if rows['job'] == 'Director':\n",
    "            dir_name = rows['name']\n",
    "    return dir_name\n",
    "\n",
    "df_credit['director_name'] = df_credit.crew.apply(director_finder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "\n",
    "df_dir_id = df_credit[['id', 'director_name']]\n",
    "df_dir_id = df_dir_id.astype({\"id\": str})\n",
    "df_rat_id = df_movies_metadata[['id', 'vote_average' ]]\n",
    "\n",
    "#merge df\n",
    "df_merge = pd.merge(df_dir_id, df_rat_id, on = 'id')\n",
    "df_best_director = df_merge.groupby('director_name').mean('vote_average')\n",
    "df_best_director = df_best_director[df_best_director['vote_average']== 10.0] \n",
    "\n",
    "print(df_best_director)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}